{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "# Doodle Classification using encoder decoder architecture\n\nA large encoder (resnet 50) is used\nThe decoder is small (custom)\nThis architecture helps reduce overfitting\nThis is not the best architecture for the competition but the data can used to try this arhitecture"
    },
    {
      "metadata": {
        "_uuid": "f7f2a9516140a84124bf7bbf538ee4c30860b778"
      },
      "cell_type": "markdown",
      "source": "## Setup\nImport the necessary libraries and a few helper functions."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ce6d2aa7de1fa341144def7d3a5b1ffdea26bc91",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nimport os\nimport ast\nimport datetime as dt\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [16, 10]\nplt.rcParams['font.size'] = 14\nimport seaborn as sns\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\nfrom tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import MobileNet\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\nstart = dt.datetime.now()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "978b1e827e598c53df3ef09838a6d85591d83052"
      },
      "cell_type": "code",
      "source": "DP_DIR = '../input/shuffle-csvs/'\nINPUT_DIR = '../input/quickdraw-doodle-recognition/'\n\nBASE_SIZE = 256\nNCSVS = 100\nNCATS = 340\nnp.random.seed(seed=1987)\ntf.set_random_seed(seed=1987)\n\ndef f2cat(filename: str) -> str:\n    return filename.split('.')[0]\n\ndef list_all_categories():\n    files = os.listdir(os.path.join(INPUT_DIR, 'train_simplified'))\n    return sorted([f2cat(f) for f in files], key=str.lower)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "b2fcd1a08ae1ae0619be38a113a244eb6515b63b"
      },
      "cell_type": "code",
      "source": "def apk(actual, predicted, k=3):\n    \"\"\"\n    Source: https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n    \"\"\"\n    if len(predicted) > k:\n        predicted = predicted[:k]\n    score = 0.0\n    num_hits = 0.0\n    for i, p in enumerate(predicted):\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits / (i + 1.0)\n    if not actual:\n        return 0.0\n    return score / min(len(actual), k)\n\ndef mapk(actual, predicted, k=3):\n    \"\"\"\n    Source: https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n    \"\"\"\n    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n\ndef preds2catids(predictions):\n    return pd.DataFrame(np.argsort(-predictions, axis=1)[:, :3], columns=['a', 'b', 'c'])\n\ndef top_3_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "264156422a95e4b350886d558d516ae8bd2e25c0"
      },
      "cell_type": "markdown",
      "source": ""
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "54e5f0c637195b6624e2f3e6db5e7f8990e14eb7"
      },
      "cell_type": "code",
      "source": "STEPS = 800\nEPOCHS = 10\nsize = 64\nbatchsize = 680",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "85ef9452aff4905979dfe64137ead96f1c8617e7"
      },
      "cell_type": "code",
      "source": "from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "256d10ae659f2423b4d8079a66e06991c7c7ff47"
      },
      "cell_type": "code",
      "source": "from tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import UpSampling2D\nfrom tensorflow.keras.layers import Conv2D\n\nfrom tensorflow.keras.layers import ZeroPadding2D\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.layers import add as Add\nfrom tensorflow.keras.layers import BatchNormalization\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1eb464ded7279e92745e194bdec98df3939ae5bf"
      },
      "cell_type": "code",
      "source": "img_input = Input(shape=(64,64,1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a3e4c9dfd690ea485e8d0c5d8a43ef5555a5bef9"
      },
      "cell_type": "code",
      "source": "\ndef identity_block(X, f, filters, stage, block):\n    \"\"\"\n    Implementation of the identity block as defined in Figure 3\n\n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string/character, used to name the layers, depending on their position in the network\n\n    Returns:\n    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n\n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    # Retrieve Filters\n    F1, F2, F3 = filters\n\n    # Save the input value. You'll need this later to add back to the main path. \n    X_shortcut = X\n\n    # First component of main path\n    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n\n    # Second component of main path \n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path \n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n    X = Add([X, X_shortcut])\n    X = Activation('relu')(X)\n\n\n    return X",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7f704c4a9252a675bd1c63d72a4bffcefb7d12e2"
      },
      "cell_type": "code",
      "source": "def convolutional_block(X, f, filters, stage, block, s=2):\n    \"\"\"\n    Implementation of the convolutional block as defined in Figure 4\n\n    Arguments:\n    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n    f -- integer, specifying the shape of the middle CONV's window for the main path\n    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n    stage -- integer, used to name the layers, depending on their position in the network\n    block -- string/character, used to name the layers, depending on their position in the network\n    s -- Integer, specifying the stride to be used\n\n    Returns:\n    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n    \"\"\"\n\n    # defining name basis\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    # Retrieve Filters\n    F1, F2, F3 = filters\n\n    # Save the input value\n    X_shortcut = X\n\n    ##### MAIN PATH #####\n    # First component of main path \n    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n    X = Activation('relu')(X)\n\n\n    # Second component of main path \n    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n    X = Activation('relu')(X)\n\n    # Third component of main path \n    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n\n    ##### SHORTCUT PATH ####\n    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1', kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n\n    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n    X = Add([X, X_shortcut])\n    X = Activation('relu')(X)\n\n    return X\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d2e6e01bc1fb2d5ad1c34faac54c74617bceff3"
      },
      "cell_type": "code",
      "source": "def ResNet50(X,input_shape=(64, 64, 3), classes=6):\n    \"\"\"\n    Implementation of the popular ResNet50 the following architecture:\n    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n\n    Arguments:\n    input_shape -- shape of the images of the dataset\n    classes -- integer, number of classes\n\n    Returns:\n    model -- a Model() instance in Keras\n    \"\"\"\n\n    # Define the input as a tensor with shape input_shape\n    #X_input = Input(input_shape)\n\n    # Zero-Padding\n    X = ZeroPadding2D((3, 3))(X)\n\n    # Stage 1\n    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n\n    # Stage 2\n    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n\n\n    # Stage 3 \n    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n\n    # Stage 4\n    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n\n    # Stage 5\n    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n\n    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n    #X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n\n\n    # output layer\n    #X = Flatten()(X)\n    #X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n\n    # Create model\n    #model = Model(inputs=X_input, outputs=X, name='ResNet50')\n\n    #return model\n    return X",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5b3ae218f17f1a73d10814b1301235549066ce65"
      },
      "cell_type": "code",
      "source": "X=ResNet50(img_input,input_shape=(64, 64, 3), classes=340)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b020fb02fe7d69b83c34dfef198d24c225633b61"
      },
      "cell_type": "code",
      "source": "#x = Conv2D(,(3,3), activation='relu', padding='same')(x)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "05d394eae9d2ac03b71d23a2f494e80107b93d7b"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d461cf77bf33b73ba751128b59b128f614924332"
      },
      "cell_type": "code",
      "source": "def decoder_block(x,blocks=6,start_filters=512):\n    for i in range(blocks):\n        x = Conv2D(start_filters//(2**i),(3,3), activation='relu', padding='same')(x)\n        x = Conv2D(start_filters//(2**i),(3,3), activation='relu', padding='same')(x)\n        x = UpSampling2D()(x)\n    return x\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "01e39c821fb65d59b31bd51819011a8e12de5f01"
      },
      "cell_type": "code",
      "source": "mpx = MaxPooling2D((2, 2), strides=(2, 2), name='b17_b6_o')(X)\n\n#X = Dense(28, name='b17_d3')(X)\n#X = Activation('sigmoid', name='predictions')(X)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c5641021a82e360b17c32e14528cf35878c30235"
      },
      "cell_type": "code",
      "source": "classes=340\nX = Flatten()(mpx)\nX = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1b85084b0a4ff41996fc0782cfb06d54f528eb5b"
      },
      "cell_type": "code",
      "source": "img_out = decoder_block(mpx,6)\n\nimg_out = Dense(1,activation='relu', name='img_out')(img_out)\n\n# Create model\nmodel = Model(img_input, [X,img_out], name='b21')\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fa2b9808f6b2f676a8c16f032b9f515d3017dd36"
      },
      "cell_type": "code",
      "source": "#from tf.keras.layers.GlobalAveragePooling2D",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d020e0d929f40024bda7bad87c493776650fa5a"
      },
      "cell_type": "code",
      "source": "\n\n#loss_funcs = {\n#    \"predictions\": brian_loss,\n#    \"img_out\": \"mse\"\n#}\nloss_weights = {\"fc340\": 1.0, \"img_out\": 10.0 } \n\n'''metrics = { \"predictions\":[\n     # weighted_binary_crossentropy,\n      \"acc\",\n      f1,\n      f2,\n      r_loss,\n      p_loss\n]}\n\n'''",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "715a303c289c50b98126c8b9f6c417ff3c7e5044"
      },
      "cell_type": "code",
      "source": "#train all\nfor i, layer in enumerate(model.layers):\n    model.layers[i].trainable = True\n\n# for i, layer in enumerate(model.layers):\n#     if orig_model.layers[i].name.startswith('b17'):\n#         model.layers[i].trainable = False\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fb233d658e56f3b4ed58556b5b696b824fdee3f6"
      },
      "cell_type": "markdown",
      "source": "model.compile(optimizer=opt,loss=loss_funcs, loss_weights=loss_weights, metrics=metrics)\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "824098fb9f487da7517d43842143f8617d57e214"
      },
      "cell_type": "markdown",
      "source": "results = model.fit_generator(train_generator,\n                              steps_per_epoch=train_df.shape[0]//BATCH_SIZE,\n                              validation_data = validation_generator,\n                              validation_steps = valid_df.shape[0]//BATCH_SIZE,\n                              epochs = 2000, \n                              callbacks=[ reduce_lr,checkpointer,tb],\n                              workers=24,\n                              max_queue_size=20)"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "0860ec35bee03f0c5cd21202dc7471c2d201cf5f",
        "_kg_hide-output": true
      },
      "cell_type": "code",
      "source": "#model = MobileNet(input_shape=(size, size, 1), alpha=1., weights=None, classes=NCATS)\nmodel.compile(optimizer=Adam(lr=0.002), loss=['categorical_crossentropy','mse'],\n              metrics=[categorical_crossentropy, categorical_accuracy],loss_weights=loss_weights)\nprint(model.summary())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "607fda05c78ab405ebfa4858893a03e88092ba12"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ab1834ea2757a53d602a3508efffcc34bc190dc7"
      },
      "cell_type": "markdown",
      "source": "## Training with Image Generator"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f6455bf9555b8381b6a4292098a64a0eb7ff54dc"
      },
      "cell_type": "code",
      "source": "def draw_cv2(raw_strokes, size=256, lw=6, time_color=True):\n    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n    for t, stroke in enumerate(raw_strokes):\n        for i in range(len(stroke[0]) - 1):\n            color = 255 - min(t, 10) * 13 if time_color else 255\n            _ = cv2.line(img, (stroke[0][i], stroke[1][i]),\n                         (stroke[0][i + 1], stroke[1][i + 1]), color, lw)\n    if size != BASE_SIZE:\n        return cv2.resize(img, (size, size))\n    else:\n        return img\n\ndef image_generator_xd(size, batchsize, ks, lw=6, time_color=True):\n    while True:\n        for k in np.random.permutation(ks):\n            filename = os.path.join(DP_DIR, 'train_k{}.csv.gz'.format(k))\n            for df in pd.read_csv(filename, chunksize=batchsize):\n                df['drawing'] = df['drawing'].apply(ast.literal_eval)\n                x = np.zeros((len(df), size, size, 1))\n                for i, raw_strokes in enumerate(df.drawing.values):\n                    x[i, :, :, 0] = draw_cv2(raw_strokes, size=size, lw=lw,\n                                             time_color=time_color)\n                x = preprocess_input(x).astype(np.float32)\n                y = keras.utils.to_categorical(df.y, num_classes=NCATS)\n                yield x, [y,x]\n\ndef df_to_image_array_xd(df, size, lw=6, time_color=True):\n    df['drawing'] = df['drawing'].apply(ast.literal_eval)\n    x = np.zeros((len(df), size, size, 1))\n    for i, raw_strokes in enumerate(df.drawing.values):\n        x[i, :, :, 0] = draw_cv2(raw_strokes, size=size, lw=lw, time_color=time_color)\n    x = preprocess_input(x).astype(np.float32)\n    return x",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98ff512e1a1b5e86e86d9eef4127525bedf3b9e1"
      },
      "cell_type": "code",
      "source": "valid_df = pd.read_csv(os.path.join(DP_DIR, 'train_k{}.csv.gz'.format(NCSVS - 1)), nrows=34000)\nx_valid = df_to_image_array_xd(valid_df, size)\ny_valid = keras.utils.to_categorical(valid_df.y, num_classes=NCATS)\nprint(x_valid.shape, y_valid.shape)\nprint('Validation array memory {:.2f} GB'.format(x_valid.nbytes / 1024.**3 ))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d80ad7f4d378ea7f30479221d604eeeed559cae4"
      },
      "cell_type": "code",
      "source": "train_datagen = image_generator_xd(size=size, batchsize=batchsize, ks=range(NCSVS - 1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6901b90a3a79adee96c433ce7d090a1448f128da"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9ce5fb89fbb77777316d6fca7689b6636c0e6021"
      },
      "cell_type": "markdown",
      "source": "x, y = next(train_datagen)\nn = 8\nfig, axs = plt.subplots(nrows=n, ncols=n, sharex=True, sharey=True, figsize=(12, 12))\nfor i in range(n**2):\n    ax = axs[i // n, i % n]\n    (-x[i]+1)/2\n    ax.imshow((-x[i, :, :, 0] + 1)/2, cmap=plt.cm.gray)\n    ax.axis('off')\nplt.tight_layout()\nfig.savefig('gs.png', dpi=300)\nplt.show();"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "da72d70fc1781e80427d45a80c07b3571dda0b36"
      },
      "cell_type": "code",
      "source": "callbacks = [\n    ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5,\n                      min_delta=0.005, mode='max', cooldown=3, verbose=1)\n]\nhists = []\nhist = model.fit_generator(\n    train_datagen, steps_per_epoch=STEPS, epochs=EPOCHS, verbose=1,\n    validation_data=(x_valid, [y_valid,x_valid]),\n    #callbacks = callbacks\n)\nhists.append(hist)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ada344bf3454765298e7b7ed7861c82bca2d2084",
        "_kg_hide-output": true,
        "_kg_hide-input": true
      },
      "cell_type": "markdown",
      "source": "hist = model.fit_generator(\n    train_datagen, steps_per_epoch=STEPS, epochs=EPOCHS, verbose=1,\n    validation_data=(x_valid, y_valid),\n    callbacks = callbacks\n)\nhists.append(hist)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a3a0cfef0d984d5b02872617e0eb2ad8a791964",
        "_kg_hide-output": true,
        "_kg_hide-input": true
      },
      "cell_type": "markdown",
      "source": "hist = model.fit_generator(\n    train_datagen, steps_per_epoch=STEPS, epochs=EPOCHS, verbose=1,\n    validation_data=(x_valid, y_valid),\n    callbacks = callbacks\n)\nhists.append(hist)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "83cbcac876c506afe90a3ce3afe7363df9b19be5"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "05767778d356bc63b7cded355159fd4082eee1a5"
      },
      "cell_type": "markdown",
      "source": "hist_df = pd.concat([pd.DataFrame(hist.history) for hist in hists], sort=True)\nhist_df.index = np.arange(1, len(hist_df)+1)\nfig, axs = plt.subplots(nrows=2, sharex=True, figsize=(16, 10))\naxs[0].plot(hist_df.val_categorical_accuracy, lw=5, label='Validation Accuracy')\naxs[0].plot(hist_df.categorical_accuracy, lw=5, label='Training Accuracy')\naxs[0].set_ylabel('Accuracy')\naxs[0].set_xlabel('Epoch')\naxs[0].grid()\naxs[0].legend(loc=0)\naxs[1].plot(hist_df.val_categorical_crossentropy, lw=5, label='Validation MLogLoss')\naxs[1].plot(hist_df.categorical_crossentropy, lw=5, label='Training MLogLoss')\naxs[1].set_ylabel('MLogLoss')\naxs[1].set_xlabel('Epoch')\naxs[1].grid()\naxs[1].legend(loc=0)\nfig.savefig('hist.png', dpi=300)\nplt.show();"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8c1927f22d3c45cba0bdee7d6f4b6c858d82d614"
      },
      "cell_type": "code",
      "source": "valid_predictions = model.predict(x_valid, batch_size=128, verbose=1)\nmap3 = mapk(valid_df[['y']].values, preds2catids(valid_predictions[0]).values)\nprint('Map3: {:.3f}'.format(map3))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "be4577a9ba00611697eea8f241a42c504981e86f"
      },
      "cell_type": "markdown",
      "source": "## Create Submission"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a7d14348150baf753e90cf2719b9f31dd564f6a2"
      },
      "cell_type": "code",
      "source": "test = pd.read_csv(os.path.join(INPUT_DIR, 'test_simplified.csv'))\ntest.head()\nx_test = df_to_image_array_xd(test, size)\nprint(test.shape, x_test.shape)\nprint('Test array memory {:.2f} GB'.format(x_test.nbytes / 1024.**3 ))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "608b02f5c7909ae62becbe5c931b7264171296e8"
      },
      "cell_type": "code",
      "source": "test_predictions = model.predict(x_test, batch_size=128, verbose=1)\n\ntop3 = preds2catids(test_predictions[0])\ntop3.head()\ntop3.shape\n\ncats = list_all_categories()\nid2cat = {k: cat.replace(' ', '_') for k, cat in enumerate(cats)}\ntop3cats = top3.replace(id2cat)\ntop3cats.head()\ntop3cats.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "23b42c5e9452ed7c2fceefb10950d51928c57c56"
      },
      "cell_type": "code",
      "source": "#test_predictions",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "52e0f9c44f2a9a38fd1550ffb9c07fb7ea22b17d"
      },
      "cell_type": "code",
      "source": "test['word'] = top3cats['a'] + ' ' + top3cats['b'] + ' ' + top3cats['c']\nsubmission = test[['key_id', 'word']]\nsubmission.to_csv('submission_{}.csv'.format(int(map3 * 10**4)), index=False)\nsubmission.head()\nsubmission.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b418f4c06c4e4453aa1b5ab16dde344eb8b735c5"
      },
      "cell_type": "code",
      "source": "end = dt.datetime.now()\nprint('Latest run {}.\\nTotal time {}s'.format(end, (end - start).seconds))",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}